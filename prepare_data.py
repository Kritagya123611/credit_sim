import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
import json

print("Starting data preparation for GNN credit risk model...")

# Load the raw dataset generated by the simulation
try:
    df = pd.read_csv("output/agents.csv")
    print(f"Successfully loaded 'agents.csv' with {df.shape[1]} columns and {df.shape[0]} agents.")
except FileNotFoundError:
    print("Error: 'output/agents.csv' not found. Please run the simulation_engine.py first.")
    exit()

# --- Define Clean Features (NO TARGET LEAKAGE) ---

# ✅ Core Risk & Financial Profile Features
core_features = [
    'risk_score',                    # Numerical risk assessment
    'economic_class',                # Socio-economic category
    'financial_personality',         # Behavioral classification
    'employment_status',             # Employment category
    'employment_verification',       # Verification status
    'income_type',                   # Income source category
    'income_pattern',                # Income regularity pattern
]

# ✅ Behavioral Scores (Numerical patterns)
behavioral_scores = [
    'device_consistency_score',      # Device usage patterns
    'ip_consistency_score',          # Location consistency
    'savings_retention_rate',        # Savings behavior
    'utility_payment_status',        # Payment reliability
    'loan_emi_payment_status',       # EMI payment behavior
]

# ✅ Digital Behavior Patterns
digital_patterns = [
    'login_pattern',                 # Account access patterns
    'ecommerce_activity_level',      # Online spending patterns
    'ecommerce_avg_ticket_size',     # Average transaction size
    'primary_digital_channels',      # Preferred payment channels
    'mobile_plan_type',              # Mobile plan category
    'sim_churn_rate',                # SIM change frequency
]

# ✅ Financial Activity Ratios & Frequencies
financial_ratios = [
    'emi_percentage',                # EMI to income ratio (if exists)
    'investment_percentage',         # Investment allocation (if exists)
    'insurance_percentage',          # Insurance spending ratio (if exists)
    'remittance_percentage',         # Money transfer ratio (if exists)
    'p2p_transfer_chance',           # P2P transfer frequency
]

# ✅ Behavioral Activity Patterns
activity_patterns = [
    'daily_work_chance',             # Work consistency
    'recharge_chance',               # Mobile recharge frequency
    'emergency_help_chance',         # Emergency behavior
    'family_support_chance',         # Family support patterns
    'professional_transfer_chance',  # Professional payment patterns
    'social_transfer_chance',        # Social transfer patterns
    'community_support_chance',      # Community support behavior
]

# ✅ Binary Indicators
binary_indicators = [
    'has_investment_activity',       # Investment activity flag
    'has_loan_emi',                  # Loan EMI flag
    'has_insurance_payments',        # Insurance payment flag
]

# ✅ FIXED: Separate identifiers and target variables
identifiers = ['agent_id']  # For graph construction only

# ✅ FIXED: Target variables (NOT features)
target_variables = ['fraud_type', 'ring_id', 'device_id']

# ✅ FIXED: Combine only CLEAN features (no target leakage)
features_to_keep = (identifiers + core_features + behavioral_scores + 
                   digital_patterns + financial_ratios + activity_patterns + 
                   binary_indicators)

print(f"Defined {len(features_to_keep)} clean features (no target leakage)")

# --- Filter DataFrame to Keep Only Clean Features ---
available_features = [col for col in features_to_keep if col in df.columns]
missing_features = [col for col in features_to_keep if col not in df.columns]

print(f"Available clean features: {len(available_features)}")
if missing_features:
    print(f"Missing features (will be skipped): {missing_features}")

# Create cleaned dataset with only pattern-based features (NO target leakage)
df_cleaned = df[available_features].copy()

# --- Separate Features and Labels Properly ---
# ✅ FIXED: Use fraud_type as label, but NOT as feature
if 'fraud_type' in df.columns:
    labels = df['fraud_type'].copy()
    print("Using 'fraud_type' as target variable")
elif 'risk_profile' in df.columns:
    labels = df['risk_profile'].copy()
    print("Using 'risk_profile' as target variable")
else:
    print("Warning: No target variable found")
    labels = None

# ✅ FIXED: Features do NOT include target variables
features = df_cleaned.copy()  # Only clean features, no targets

print(f"Final feature set: {len(features.columns)} features")
print(f"Features: {list(features.columns)}")

# --- Feature Engineering for GNN ---

# ✅ FIXED: Proper categorical feature identification
categorical_features = [
    'economic_class',
    'financial_personality', 
    'employment_status',
    'employment_verification',
    'income_type',
    'income_pattern',
    'savings_retention_rate',
    'utility_payment_status',
    'loan_emi_payment_status',
    'login_pattern',
    'ecommerce_activity_level',
    'ecommerce_avg_ticket_size',
    'primary_digital_channels',
    'mobile_plan_type',
    'sim_churn_rate'
]

# Filter to only existing categorical features
categorical_columns = [col for col in categorical_features if col in features.columns]
print(f"Encoding {len(categorical_columns)} categorical features...")

label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    # Handle missing values
    features[col] = features[col].fillna('Unknown')
    features[col] = le.fit_transform(features[col])
    label_encoders[col] = le

# ✅ FIXED: Proper numerical feature identification
numerical_features = [
    'risk_score',
    'device_consistency_score',
    'ip_consistency_score',
    'emi_percentage',
    'investment_percentage', 
    'insurance_percentage',
    'remittance_percentage',
    'p2p_transfer_chance',
    'daily_work_chance',
    'recharge_chance',
    'emergency_help_chance',
    'family_support_chance',
    'professional_transfer_chance',
    'social_transfer_chance',
    'community_support_chance'
]

# Filter to only existing numerical features
numerical_columns = [col for col in numerical_features if col in features.columns]
print(f"Processing {len(numerical_columns)} numerical features...")

# Fill missing values with median for numerical columns
for col in numerical_columns:
    median_val = features[col].median()
    features[col] = features[col].fillna(median_val)

# ✅ FIXED: Normalize numerical features (excluding agent_id)
scaler = StandardScaler()
features_to_scale = [col for col in numerical_columns if col != 'agent_id']

if features_to_scale:
    features[features_to_scale] = scaler.fit_transform(features[features_to_scale])
    print(f"Normalized {len(features_to_scale)} numerical features")

# ✅ Handle binary features
binary_columns = [col for col in binary_indicators if col in features.columns]
for col in binary_columns:
    # Ensure binary features are 0/1
    features[col] = features[col].astype(int)

print(f"Processed {len(binary_columns)} binary features")

# --- Data Quality Checks ---
print("\n=== Data Quality Report ===")
print(f"Total agents: {len(features)}")
print(f"Total features: {len(features.columns)}")
print(f"Missing values: {features.isnull().sum().sum()}")

if labels is not None:
    print(f"Target distribution:")
    print(labels.value_counts(dropna=False))
    
    # Check for class imbalance
    if len(labels.value_counts(dropna=False)) > 1:
        min_class_ratio = labels.value_counts(dropna=False).min() / len(labels)
        print(f"Minimum class ratio: {min_class_ratio:.3f}")
        if min_class_ratio < 0.05:
            print("Warning: Severe class imbalance detected")

# --- Feature Categories Summary ---
print("\n=== Feature Categories Summary ===")
feature_categories = {
    'Core Profile': [col for col in core_features if col in features.columns],
    'Behavioral Scores': [col for col in behavioral_scores if col in features.columns],
    'Digital Patterns': [col for col in digital_patterns if col in features.columns],
    'Financial Ratios': [col for col in financial_ratios if col in features.columns],
    'Activity Patterns': [col for col in activity_patterns if col in features.columns],
    'Binary Indicators': [col for col in binary_indicators if col in features.columns]
}

for category, cols in feature_categories.items():
    print(f"{category}: {len(cols)} features")

# --- Save Processed Data ---
output_dir = "output"

# Save cleaned features ready for GNN training
features.to_csv(f"{output_dir}/gnn_features.csv", index=False)
print(f"\nSaved GNN-ready features to '{output_dir}/gnn_features.csv'")

# Save labels if available
if labels is not None:
    labels.to_csv(f"{output_dir}/gnn_labels.csv", index=False, header=True)
    print(f"Saved labels to '{output_dir}/gnn_labels.csv'")

# ✅ FIXED: Corrected feature metadata
feature_metadata = {
    'feature_names': list(features.columns),
    'categorical_features': categorical_columns,  # Only actual categorical features
    'numerical_features': numerical_columns,     # Only actual numerical features
    'binary_features': binary_columns,           # Only binary features
    'feature_categories': feature_categories,
    'total_features': len(features.columns),
    'total_agents': len(features),
    'target_variable': 'fraud_type' if 'fraud_type' in df.columns else 'risk_profile',
    'excluded_features': target_variables  # Document what was excluded
}

with open(f"{output_dir}/feature_metadata.json", 'w') as f:
    json.dump(feature_metadata, f, indent=2)
print(f"Saved feature metadata to '{output_dir}/feature_metadata.json'")

# --- Generate Feature Summary for GNN Model ---
print("\n=== GNN Model Ready Summary ===")
print(f"✅ Node features: {len(features.columns)} dimensions")
print(f"✅ Agent nodes: {len(features)} total")
if labels is not None:
    print(f"✅ Target classes: {len(labels.value_counts(dropna=False))}")
print(f"✅ Data type: Pattern-based features (no keyword learning)")
print(f"✅ NO target leakage: fraud_type, ring_id, device_id excluded from features")
print(f"✅ Clean feature categories: {len(feature_categories)} categories")
print(f"✅ Ready for graph construction with transaction data")

print("\nData preparation complete! Ready for GNN training.")
