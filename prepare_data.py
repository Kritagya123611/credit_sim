import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
import json

print("Starting data preparation for GNN credit risk model...")

# Load the raw dataset generated by the simulation
try:
    df = pd.read_csv("output/agents.csv")
    print(f"Successfully loaded 'agents.csv' with {df.shape[1]} columns and {df.shape[0]} agents.")
except FileNotFoundError:
    print("Error: 'output/agents.csv' not found. Please run the simulation_engine.py first.")
    exit()

# --- Define Clean Features (NO TARGET LEAKAGE, NO KEYWORDS) ---

# ‚úÖ Core Risk & Financial Profile Features (NUMERICAL/ENCODED ONLY)
core_features = [
    'economic_class',                # Socio-economic category (encoded)
    'financial_personality',         # Behavioral classification (encoded)
    'employment_status',             # Employment category (encoded)
    'employment_verification',       # Verification status (encoded)
    'income_type',                   # Income source category (encoded)
    'income_pattern',                # Income regularity pattern (encoded)
]

# ‚úÖ Behavioral Scores (Pure numerical patterns - NO KEYWORDS)
behavioral_scores = [
    'device_consistency_score',      # Device usage patterns (0-1 score)
    'ip_consistency_score',          # Location consistency (0-1 score)
    'savings_retention_rate',        # Savings behavior (encoded level)
    'utility_payment_status',        # Payment reliability (encoded)
    'loan_emi_payment_status',       # EMI payment behavior (encoded)
]

# ‚úÖ Digital Behavior Patterns (Encoded behavioral indicators)
digital_patterns = [
    'login_pattern',                 # Account access patterns (encoded)
    'ecommerce_activity_level',      # Online spending patterns (encoded)
    'ecommerce_avg_ticket_size',     # Average transaction size (encoded)
    'primary_digital_channels',      # Preferred payment channels (encoded)
    'mobile_plan_type',              # Mobile plan category (encoded)
    'sim_churn_rate',                # SIM change frequency (encoded)
]

# ‚úÖ Financial Activity Ratios & Frequencies (Pure numerical)
financial_ratios = [
    'emi_percentage',                # EMI to income ratio
    'investment_percentage',         # Investment allocation
    'insurance_percentage',          # Insurance spending ratio
    'remittance_percentage',         # Money transfer ratio
    'p2p_transfer_chance',           # P2P transfer frequency
]

# ‚úÖ Behavioral Activity Patterns (Probability scores - NO KEYWORDS)
activity_patterns = [
    'daily_work_chance',             # Work consistency (0-1 probability)
    'recharge_chance',               # Mobile recharge frequency (0-1 probability)
    'emergency_help_chance',         # Emergency behavior (0-1 probability)
    'family_support_chance',         # Family support patterns (0-1 probability)
    'professional_transfer_chance',  # Professional payment patterns (0-1 probability)
    'social_transfer_chance',        # Social transfer patterns (0-1 probability)
    'community_support_chance',      # Community support behavior (0-1 probability)
]

# ‚úÖ Binary Indicators (0/1 flags - NO KEYWORDS)
binary_indicators = [
    'has_investment_activity',       # Investment activity flag (0/1)
    'has_loan_emi',                  # Loan EMI flag (0/1)
    'has_insurance_payments',        # Insurance payment flag (0/1)
]

# ‚úÖ Node identifier (for graph construction only)
identifiers = ['agent_id']

# ‚úÖ Target variables for credit risk (NOT features - separate labels)
credit_risk_targets = ['risk_score', 'risk_profile']

# ‚úÖ EXCLUDED: No keyword-based or target leakage features
excluded_features = [
    'fraud_type', 'ring_id', 'device_id',        # Fraud-related (not credit risk)
    'archetype_name',                             # Keyword-based archetype
    'name', 'email', 'account_no',               # Direct identifiers
    'risk_score',                                 # Target variable (separate)
    'risk_profile'                                # Target variable (separate)
]

# ‚úÖ Combine only CLEAN pattern-based features
features_to_keep = (identifiers + core_features + behavioral_scores + 
                   digital_patterns + financial_ratios + activity_patterns + 
                   binary_indicators)

print(f"Defined {len(features_to_keep)} clean pattern-based features")
print(f"Excluded keyword/leakage features: {excluded_features}")

# --- Filter DataFrame to Keep Only Clean Features ---
available_features = [col for col in features_to_keep if col in df.columns]
missing_features = [col for col in features_to_keep if col not in df.columns]

print(f"Available clean features: {len(available_features)}")
if missing_features:
    print(f"Missing features (will be skipped): {missing_features}")

# Create cleaned dataset with only pattern-based features
df_cleaned = df[available_features].copy()

# --- Extract Credit Risk Labels (Separate from Features) ---
credit_risk_labels = {}

# Primary target: Risk score (continuous 0-1)
if 'risk_score' in df.columns:
    credit_risk_labels['risk_score'] = df['risk_score'].copy()
    print("‚úÖ Extracted 'risk_score' as primary target (regression)")

# Secondary target: Risk profile (categorical)
if 'risk_profile' in df.columns:
    credit_risk_labels['risk_profile'] = df['risk_profile'].copy()
    print("‚úÖ Extracted 'risk_profile' as secondary target (classification)")

# Keep fraud labels for validation/comparison (but NOT for training)
if 'fraud_type' in df.columns:
    credit_risk_labels['fraud_type'] = df['fraud_type'].copy()
    print("‚ÑπÔ∏è Kept 'fraud_type' for validation (not used in training)")

# ‚úÖ Features contain ONLY behavioral patterns (no targets, no keywords)
features = df_cleaned.copy()

print(f"Final feature set: {len(features.columns)} dimensions")
print(f"Credit risk targets: {list(credit_risk_labels.keys())}")

# --- Feature Engineering for GNN (NO KEYWORD DEPENDENCIES) ---

# ‚úÖ Categorical features (will be label encoded to numbers)
categorical_features = [
    'economic_class',
    'financial_personality', 
    'employment_status',
    'employment_verification',
    'income_type',
    'income_pattern',
    'savings_retention_rate',
    'utility_payment_status',
    'loan_emi_payment_status',
    'login_pattern',
    'ecommerce_activity_level',
    'ecommerce_avg_ticket_size',
    'primary_digital_channels',
    'mobile_plan_type',
    'sim_churn_rate'
]

# Filter to existing categorical features and encode
categorical_columns = [col for col in categorical_features if col in features.columns]
print(f"Encoding {len(categorical_columns)} categorical features to numbers...")

label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    # Handle missing values
    features[col] = features[col].fillna('Unknown')
    features[col] = le.fit_transform(features[col])
    label_encoders[col] = le

# ‚úÖ Numerical features (pure behavioral scores and ratios)
numerical_features = [
    'device_consistency_score',
    'ip_consistency_score',
    'emi_percentage',
    'investment_percentage', 
    'insurance_percentage',
    'remittance_percentage',
    'p2p_transfer_chance',
    'daily_work_chance',
    'recharge_chance',
    'emergency_help_chance',
    'family_support_chance',
    'professional_transfer_chance',
    'social_transfer_chance',
    'community_support_chance'
]

# Filter to existing numerical features
numerical_columns = [col for col in numerical_features if col in features.columns]
print(f"Processing {len(numerical_columns)} numerical behavioral features...")

# Fill missing values with median
for col in numerical_columns:
    median_val = features[col].median()
    features[col] = features[col].fillna(median_val)

# ‚úÖ Normalize numerical features (standardize to mean=0, std=1)
scaler = StandardScaler()
features_to_scale = [col for col in numerical_columns if col != 'agent_id']

if features_to_scale:
    features[features_to_scale] = scaler.fit_transform(features[features_to_scale])
    print(f"Normalized {len(features_to_scale)} numerical features")

# ‚úÖ Binary features (ensure 0/1 encoding)
binary_columns = [col for col in binary_indicators if col in features.columns]
for col in binary_columns:
    # Convert to integer 0/1
    features[col] = features[col].astype(int)

print(f"Processed {len(binary_columns)} binary features")

# --- Data Quality Checks ---
print("\n=== Data Quality Report ===")
print(f"Total agents: {len(features)}")
print(f"Total features: {len(features.columns)}")
print(f"Missing values: {features.isnull().sum().sum()}")

# ‚úÖ Credit Risk Target Analysis
if 'risk_score' in credit_risk_labels:
    risk_scores = credit_risk_labels['risk_score']
    print(f"\nRisk Score Distribution:")
    print(f"  Mean: {risk_scores.mean():.3f}")
    print(f"  Std: {risk_scores.std():.3f}")
    print(f"  Range: [{risk_scores.min():.3f}, {risk_scores.max():.3f}]")

if 'risk_profile' in credit_risk_labels:
    risk_profiles = credit_risk_labels['risk_profile']
    print(f"\nRisk Profile Distribution:")
    print(risk_profiles.value_counts())
    
    # Check for class imbalance
    min_class_ratio = risk_profiles.value_counts().min() / len(risk_profiles)
    print(f"Minimum class ratio: {min_class_ratio:.3f}")
    if min_class_ratio < 0.05:
        print("‚ö†Ô∏è Warning: Severe class imbalance detected")

# --- Feature Categories Summary ---
print("\n=== Feature Categories Summary ===")
feature_categories = {
    'Core Profile': [col for col in core_features if col in features.columns],
    'Behavioral Scores': [col for col in behavioral_scores if col in features.columns],
    'Digital Patterns': [col for col in digital_patterns if col in features.columns],
    'Financial Ratios': [col for col in financial_ratios if col in features.columns],
    'Activity Patterns': [col for col in activity_patterns if col in features.columns],
    'Binary Indicators': [col for col in binary_indicators if col in features.columns]
}

for category, cols in feature_categories.items():
    print(f"{category}: {len(cols)} features")

# --- Save Processed Data ---
output_dir = "output"

# Save clean features (NO keywords, NO target leakage)
features.to_csv(f"{output_dir}/gnn_features.csv", index=False)
print(f"\n‚úÖ Saved GNN-ready features to '{output_dir}/gnn_features.csv'")

# Save credit risk labels separately
for label_name, label_data in credit_risk_labels.items():
    label_data.to_csv(f"{output_dir}/gnn_labels_{label_name}.csv", index=False, header=True)
    print(f"‚úÖ Saved {label_name} labels to '{output_dir}/gnn_labels_{label_name}.csv'")

# ‚úÖ Feature metadata for credit risk model
feature_metadata = {
    'feature_names': list(features.columns),
    'categorical_features': categorical_columns,
    'numerical_features': numerical_columns,
    'binary_features': binary_columns,
    'feature_categories': feature_categories,
    'total_features': len(features.columns),
    'total_agents': len(features),
    'primary_target': 'risk_score',           # Credit risk regression
    'secondary_target': 'risk_profile',       # Credit risk classification
    'excluded_features': excluded_features,   # Document exclusions
    'encoding_info': {
        'categorical_encoded': True,
        'numerical_normalized': True,
        'binary_as_int': True
    }
}

with open(f"{output_dir}/feature_metadata.json", 'w') as f:
    json.dump(feature_metadata, f, indent=2)
print(f"‚úÖ Saved feature metadata to '{output_dir}/feature_metadata.json'")

# --- Final Validation ---
print("\n=== Credit Risk GNN Model Ready Summary ===")
print(f"‚úÖ Node features: {len(features.columns)} dimensions")
print(f"‚úÖ Agent nodes: {len(features)} total")
print(f"‚úÖ Primary target: Risk score (continuous 0-1) for regression")
print(f"‚úÖ Secondary target: Risk profile (categorical) for classification")
print(f"‚úÖ Feature types: Pattern-based behavioral scores (NO keywords)")
print(f"‚úÖ NO target leakage: All targets excluded from features")
print(f"‚úÖ NO archetype keywords: Removed archetype_name and similar")
print(f"‚úÖ Encoded categoricals: All categorical features converted to numbers")
print(f"‚úÖ Normalized features: All numerical features standardized")
print(f"‚úÖ Ready for graph-based credit risk assessment")

print("\nüéØ Data preparation complete! Ready for credit risk GNN training.")
